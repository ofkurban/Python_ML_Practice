# Python_ML_Practice
Iris Flower Classification
Iris flower dataset perhaps is the best-known data set in the classification literature. It aims to classify iris flowers among three species (setosa, versicolor or virginica) based on measurements of length and width of sepals and petals.

1. Summary with Statistics and Visualization
When come across new dataset, we can take a look at its dimensions, first several rows, attribute type, statistical summary of each attribute and class distribution.

print(data.shape)
print(data.head(10))
print(data.dtype)
print(data.describe())
print(data.groupby('class').size())

In summary, in this iris dataset, we have 150 instances, 5 attributes (sepal-length, sepal-width, petal-length, petal-width and class) and 3 classes (sepal-length, Iris-versicolor and Iris-virginica). Among these 5 attributes, sepal-length, sepal-width, petal-length and petal-width are numeric while class attribute is string data. Besides, in each category there are 50 instances.

After having a basic idea about the data, let's dig deeper through visualizations. Generally, univariate plots help to better understand each attribute, while multivariate plots is good to understand the relationships between attributes.

•	Box plots 
•	Histogram

It looks like perhaps two of the input variables (sepal-length and sepal-width) have a Gaussian distribution 

•	Scatter plot matrix Take a look at the interactions between the variables. It shows that there is a high correlation and a predictable relationship.  
2. Algorithms Evaluation

Now it's time to create model and make prediction on unseen data.
•	Separate dataset and Test In this problem, we will split the loaded dataset into two, 80% of which we will use to train our models and 20% that we will hold back as a validation datas. Also, it will be a 10-fold cross validation to estimate accuracy.

•	Build models From the plots, we deduce that some of the classes are partially linearly separable in some dimensions. Let’s evaluate six different algorithms:

i.	Logistic Regression (LR)
ii.	Linear Discriminant Analysis (LDA)
iii.	k-Nearest Neighbors (KNN).
iv.	Classification and Regression Trees (CART).
v.	Gaussian Naive Bayes (NB).
vi.	Support Vector Machines (SVM). We reset the random number seed before each run to ensure that the evaluation of each algorithm is performed using exactly the same data splits.

 LR: 0.966667 (std: 0.040825)
 LDA: 0.975000 (std: 0.038188)
 KNN: 0.983333 (std: 0.033333) **
 CART: 0.975000 (std: 0.038188)
 NB: 0.975000 (std: 0.053359)
 SVM: 0.981667 (std: 0.025000)

It looks that KNN achieves the highest accuracy score. Draw this result using boxplot. 

•	Make Prediction

Since KNN is the most accurate model for iris classification problem, we run the KNN model directly on the validation set and summarize the results as a final accuracy score, a confusion matrix and a classification report.
0.9  

The accuracy is 0.9.

   [[ 7 0 0] 
    [ 0 11 1] 
    [ 0 2 9]] 
The confusion matrix shows that there are 3 errors made
                     precision    recall  f1-score   support

        Iris-setosa       1.00      1.00      1.00         7
    Iris-versicolor       0.85      0.92      0.88        12
     Iris-virginica       0.90      0.82      0.86        11

        avg / total       0.90      0.90      0.90        30

